name: Blacksmith Docker Build Benchmark

on:
  workflow_dispatch:
    inputs:
      repeats:
        description: "Repetitions per runner (1-3)"
        required: true
        default: "1"
        type: choice
        options:
          - "1"
          - "2"
          - "3"

permissions:
  contents: read

jobs:
  no_cache:
    name: no-cache / ${{ matrix.runner }}
    runs-on: ${{ matrix.runner }}
    timeout-minutes: 90
    strategy:
      fail-fast: false
      matrix:
        runner:
          - ubuntu-latest
          - blacksmith-2vcpu-ubuntu-2404
          - blacksmith-4vcpu-ubuntu-2404
          - blacksmith-8vcpu-ubuntu-2404
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Benchmark no-cache builds
        shell: bash
        run: |
          set -euo pipefail

          runner_slug="${{ matrix.runner }}"
          repeats="${{ github.event.inputs.repeats }}"
          out_dir="bench-results"
          mkdir -p "${out_dir}"

          cpu_model="$(lscpu | awk -F: '/Model name/{gsub(/^ +/,"",$2); print $2; exit}')"
          nproc_count="$(nproc)"

          for repeat in $(seq 1 "${repeats}"); do
            out_file="${out_dir}/no-cache-${runner_slug}-r${repeat}.json"

            start_ns="$(date +%s%N)"
            docker buildx build \
              --progress=plain \
              --no-cache \
              --provenance=false \
              --sbom=false \
              --file docker/Dockerfile \
              .
            end_ns="$(date +%s%N)"

            duration_s="$(awk -v start="${start_ns}" -v end="${end_ns}" 'BEGIN { printf "%.3f", (end - start) / 1000000000 }')"

            jq -n \
              --arg phase "no_cache" \
              --arg runner "${{ matrix.runner }}" \
              --argjson repeat "${repeat}" \
              --argjson duration_seconds "${duration_s}" \
              --argjson nproc "${nproc_count}" \
              --arg cpu_model "${cpu_model}" \
              --arg run_id "${{ github.run_id }}" \
              --arg sha "${{ github.sha }}" \
              '{phase:$phase, runner:$runner, repeat:$repeat, duration_seconds:$duration_seconds, nproc:$nproc, cpu_model:$cpu_model, run_id:$run_id, sha:$sha}' > "${out_file}"
          done

      - name: Upload no-cache results
        uses: actions/upload-artifact@v4
        with:
          name: bench-result-no-cache-${{ matrix.runner }}
          path: bench-results/no-cache-${{ matrix.runner }}-r*.json
          if-no-files-found: error

  cache_populate:
    name: cache-populate / ${{ matrix.runner }}
    runs-on: ${{ matrix.runner }}
    timeout-minutes: 90
    strategy:
      fail-fast: false
      matrix:
        runner:
          - ubuntu-latest
          - blacksmith-2vcpu-ubuntu-2404
          - blacksmith-4vcpu-ubuntu-2404
          - blacksmith-8vcpu-ubuntu-2404
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Populate GHA cache builds
        shell: bash
        run: |
          set -euo pipefail

          runner_slug="${{ matrix.runner }}"
          repeats="${{ github.event.inputs.repeats }}"
          out_dir="bench-results"
          mkdir -p "${out_dir}"

          cpu_model="$(lscpu | awk -F: '/Model name/{gsub(/^ +/,"",$2); print $2; exit}')"
          nproc_count="$(nproc)"

          for repeat in $(seq 1 "${repeats}"); do
            scope="bench-${{ github.run_id }}-${runner_slug}-r${repeat}"
            out_file="${out_dir}/cache-populate-${runner_slug}-r${repeat}.json"

            start_ns="$(date +%s%N)"
            docker buildx build \
              --progress=plain \
              --provenance=false \
              --sbom=false \
              --cache-from type=gha,scope="${scope}" \
              --cache-to type=gha,mode=max,scope="${scope}" \
              --file docker/Dockerfile \
              .
            end_ns="$(date +%s%N)"

            duration_s="$(awk -v start="${start_ns}" -v end="${end_ns}" 'BEGIN { printf "%.3f", (end - start) / 1000000000 }')"

            jq -n \
              --arg phase "cache_populate" \
              --arg runner "${{ matrix.runner }}" \
              --argjson repeat "${repeat}" \
              --argjson duration_seconds "${duration_s}" \
              --arg cache_scope "${scope}" \
              --argjson nproc "${nproc_count}" \
              --arg cpu_model "${cpu_model}" \
              --arg run_id "${{ github.run_id }}" \
              --arg sha "${{ github.sha }}" \
              '{phase:$phase, runner:$runner, repeat:$repeat, duration_seconds:$duration_seconds, cache_scope:$cache_scope, nproc:$nproc, cpu_model:$cpu_model, run_id:$run_id, sha:$sha}' > "${out_file}"
          done

      - name: Upload cache-populate results
        uses: actions/upload-artifact@v4
        with:
          name: bench-result-cache-populate-${{ matrix.runner }}
          path: bench-results/cache-populate-${{ matrix.runner }}-r*.json
          if-no-files-found: error

  cache_warm:
    name: cache-warm / ${{ matrix.runner }}
    needs: cache_populate
    runs-on: ${{ matrix.runner }}
    timeout-minutes: 90
    strategy:
      fail-fast: false
      matrix:
        runner:
          - ubuntu-latest
          - blacksmith-2vcpu-ubuntu-2404
          - blacksmith-4vcpu-ubuntu-2404
          - blacksmith-8vcpu-ubuntu-2404
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Benchmark warm-cache builds
        shell: bash
        run: |
          set -euo pipefail

          runner_slug="${{ matrix.runner }}"
          repeats="${{ github.event.inputs.repeats }}"
          out_dir="bench-results"
          mkdir -p "${out_dir}"

          cpu_model="$(lscpu | awk -F: '/Model name/{gsub(/^ +/,"",$2); print $2; exit}')"
          nproc_count="$(nproc)"

          for repeat in $(seq 1 "${repeats}"); do
            scope="bench-${{ github.run_id }}-${runner_slug}-r${repeat}"
            out_file="${out_dir}/cache-warm-${runner_slug}-r${repeat}.json"

            start_ns="$(date +%s%N)"
            docker buildx build \
              --progress=plain \
              --provenance=false \
              --sbom=false \
              --cache-from type=gha,scope="${scope}" \
              --cache-to type=gha,mode=max,scope="${scope}" \
              --file docker/Dockerfile \
              .
            end_ns="$(date +%s%N)"

            duration_s="$(awk -v start="${start_ns}" -v end="${end_ns}" 'BEGIN { printf "%.3f", (end - start) / 1000000000 }')"

            jq -n \
              --arg phase "cache_warm" \
              --arg runner "${{ matrix.runner }}" \
              --argjson repeat "${repeat}" \
              --argjson duration_seconds "${duration_s}" \
              --arg cache_scope "${scope}" \
              --argjson nproc "${nproc_count}" \
              --arg cpu_model "${cpu_model}" \
              --arg run_id "${{ github.run_id }}" \
              --arg sha "${{ github.sha }}" \
              '{phase:$phase, runner:$runner, repeat:$repeat, duration_seconds:$duration_seconds, cache_scope:$cache_scope, nproc:$nproc, cpu_model:$cpu_model, run_id:$run_id, sha:$sha}' > "${out_file}"
          done

      - name: Upload cache-warm results
        uses: actions/upload-artifact@v4
        with:
          name: bench-result-cache-warm-${{ matrix.runner }}
          path: bench-results/cache-warm-${{ matrix.runner }}-r*.json
          if-no-files-found: error

  summary:
    name: Benchmark summary
    needs: [no_cache, cache_populate, cache_warm]
    runs-on: ubuntu-latest
    if: ${{ always() }}
    steps:
      - name: Download all benchmark artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: bench-result-*
          path: bench-results
          merge-multiple: true

      - name: Generate summary table
        shell: bash
        run: |
          set -euo pipefail

          python3 - <<'PY'
          import json
          import statistics
          from pathlib import Path

          result_files = sorted(Path("bench-results").glob("*.json"))
          if not result_files:
              raise SystemExit("No benchmark result files found")

          rows = []
          for fp in result_files:
              with fp.open() as f:
                  rows.append(json.load(f))

          rows = [r for r in rows if isinstance(r.get("duration_seconds"), (int, float))]
          if not rows:
              raise SystemExit("No benchmark rows with duration data found")

          phases = ["no_cache", "cache_populate", "cache_warm"]
          runners = [
              "ubuntu-latest",
              "blacksmith-2vcpu-ubuntu-2404",
              "blacksmith-4vcpu-ubuntu-2404",
              "blacksmith-8vcpu-ubuntu-2404",
          ]

          by_key = {}
          for r in rows:
              by_key.setdefault((r["phase"], r["runner"]), []).append(r["duration_seconds"])

          summary_lines = []
          summary_lines.append("## Docker build benchmark summary")
          summary_lines.append("")
          summary_lines.append("| Phase | Runner | N | Avg (s) | Median (s) | Min (s) | Max (s) |")
          summary_lines.append("|---|---|---:|---:|---:|---:|---:|")

          for phase in phases:
              for runner in runners:
                  vals = by_key.get((phase, runner), [])
                  if not vals:
                      continue
                  summary_lines.append(
                      f"| {phase} | {runner} | {len(vals)} | {statistics.mean(vals):.3f} | {statistics.median(vals):.3f} | {min(vals):.3f} | {max(vals):.3f} |"
                  )

          summary_lines.append("")
          summary_lines.append("| Phase | Runner | Median speedup vs ubuntu-latest |")
          summary_lines.append("|---|---|---:|")
          for phase in phases:
              base = by_key.get((phase, "ubuntu-latest"), [])
              if not base:
                  continue
              base_median = statistics.median(base)
              for runner in runners:
                  vals = by_key.get((phase, runner), [])
                  if not vals:
                      continue
                  med = statistics.median(vals)
                  speedup = base_median / med if med else 0.0
                  summary_lines.append(f"| {phase} | {runner} | {speedup:.2f}x |")

          summary_lines.append("")
          summary_lines.append("### Runner metadata samples")
          summary_lines.append("")
          summary_lines.append("| Phase | Runner | Repeat | nproc | CPU model | Duration (s) |")
          summary_lines.append("|---|---|---:|---:|---|---:|")
          for r in sorted(rows, key=lambda x: (x["phase"], x["runner"], x["repeat"])):
              summary_lines.append(
                  f"| {r['phase']} | {r['runner']} | {r['repeat']} | {r.get('nproc','')} | {r.get('cpu_model','')} | {r['duration_seconds']:.3f} |"
              )

          text = "\n".join(summary_lines) + "\n"
          Path("benchmark-summary.md").write_text(text)
          print(text)
          PY

          cat benchmark-summary.md >> "$GITHUB_STEP_SUMMARY"

      - name: Upload benchmark summary
        uses: actions/upload-artifact@v4
        with:
          name: bench-summary
          path: benchmark-summary.md
          if-no-files-found: error
